import os
import pandas as pd

##### Set up #####
configfile: "./config/main_config.yaml"

# Make sure the dataset exists and a workflow for creating a so object also
supported_datasets = {
    "jackson": "0_make_so_jackson/Snakefile"
}
assert os.path.exists(config["root"])
dataset_name = os.path.basename(config["root"])

##### Define path variables form config #####
root=config["root"]
prediction_target=config["prediction_target"]
normalized_with=f"normalized_with_{config['normalize_with']}"
split_how=config["split_how"]

##### Helper functions #####
include: "rules/helper_functions.smk"

##### Load other rules #####
# Usefule when wnting to run the workflow in chunks.

# MLflow
#include: "rules/delete_mlflow_runs.smk" # Delete some mlflow run. Dont use unless you know what you are donig.
#include: "rules/parse_pretrain_mlflow_runs.smk" # Checks against mlflow if all concept configs combinations have been pretrained.
#include: "rules/parse_train_mlflow_runs.smk" # Parse the train runs.

# Normalize data
include: "rules/normalize_all_folds.smk"

# Gen datasets
include: "rules/gen_all_datasets.smk" # Generates all concept graph datasets.
# include: "rules/gen_all_rand_datasets.smk" # Generates all random concept graph datasets.

# Attribute graphs
include: "rules/gen_all_attributed_graphs.smk"

# Pretrain
include: "rules/pretrain_all.smk" # Pretrains all models
# include: "rules/pretrain_all_rnd.smk" # Pretrain selected randomly permuted models. s

# Train
# include: "rules/train_all.smk" # Train all models.
# include: "rules/train_end2end_gcls.smk" # Train al the end2end models.

# Train baselines
# include: "rules/train_all_space_gm.smk" # Run all the space gm training configurations.

# Train multiple seeds
# include: "rules/train_best_space_gm.smk"
# include: "rules/train_best_concepts.smk"
# include: "rules/train_best_gcls.smk"
# include: "rules/train_rnd_concepts.smk"
# include: "rules/train_rnd_gcls.smk"

##### Load workflow rules #####
# Include baselines
# include: "00_baselines_non_geom/Snakefile"

# Make so object out of raw Jakson dataset.
include: supported_datasets[dataset_name]

# Filter samples based on defined concepts
include: "1_filter_samples/Snakefile"

# Split into train test and val.
include: "2_split_samples/Snakefile"

# Normalize data as specified in the config.
include: "3_normalize/Snakefile"

# Generate datasets
include: "4_generate_graph_datasets/Snakefile"

# Attribute graphs and saves them as python geometric Data class objects
include: "5_attribute/Snakefile"

# Pretrain gnn models for the graph concept learner and
include: "6_pretrain/Snakefile"

# Generate tables with results and get paths to best models
include: "7_model_selection/Snakefile"

# train the graph concept learner.
include: "8_train/Snakefile"

# Randomization sanity check
# include: "80_rand_sanity_check/Snakefile"

# Train models with rando seed
# include: "81_train_seeds/Snakefile"
