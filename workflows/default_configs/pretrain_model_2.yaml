act: ReLU
act_first: false
batch_size: 8
dropout: false
gnn: GIN
jk: null
lr: 0.0001
n_epoch: 100
norm: BatchNorm
num_layers: 2
num_layers_MLP: 2
optim: Adam
pool: global_add_pool
scaler: 2
scheduler:
- ExponentialLR
- 0.98
seed: 1
